%[AUTOGENERATED]
function [ratios, LCOE, LCOE_nom, P_var, P_var_nom, ...
             param_names, num_DVs, X_LCOE, X_LCOE_nom, ...
             dvar_names, X_Pvar, X_Pvar_nom,...
             slope_LCOE_norm, slope_Pvar_norm, ...
             slope_X_LCOE_norm, slope_X_Pvar_norm, ...
             T, par_J_par_p_post_optim, ...
             dJ_star_dp_quad_post_optim, dJ_star_dp_lin_post_optim,...
             dJstar_dp_re_optim, par_x_star_par_p_post_optim, ...
             par_x_star_par_p_re_optim, ...
             delta_p_change_activity_post_optim, ...
             delta_p_change_activity_re_optim,...
             runtime_post_optim, runtime_re_optim] = param_sweep(filename_uuid)
% Function param_sweep
%
% :param filename_uuid: filename_uuid
% :returns: ratios
% :returns: Levelized cost of energy ($/kWh)
% :returns: LCOE_nom
% :returns: P_var
% :returns: P_var_nom
% :returns: param_names
% :returns: num_DVs
% :returns: X_LCOE
% :returns: X_LCOE_nom
% :returns: dvar_names
% :returns: X_Pvar
% :returns: X_Pvar_nom
% :returns: slope_LCOE_norm
% :returns: slope_Pvar_norm
% :returns: slope_X_LCOE_norm
% :returns: slope_X_Pvar_norm
% :returns: wave energy period (s)
% :returns: par_J_par_p_post_optim
% :returns: dJ_star_dp_quad_post_optim
% :returns: dJ_star_dp_lin_post_optim
% :returns: dJstar_dp_re_optim
% :returns: par_x_star_par_p_post_optim
% :returns: par_x_star_par_p_re_optim
% :returns: $\\delta$ p change activity post optim
% :returns: $\\delta$ p change activity re optim
% :returns: runtime_post_optim
% :returns: runtime_re_optim

    %% Setup
    b = var_bounds();
    if nargin>0
        b.filename_uuid = filename_uuid;
    end
    [p,T] = parameters();
    
    param_names = T.name_pretty(T.sweep);  % list of parameters to sweep
    params = T.name(T.sweep);
    p_val  = [T.value_normalize{T.sweep}];
    p_idxs = T.index_normalize(T.sweep);

    dvar_names = b.var_names_pretty(1:end-1);
    
    %%
    % use the optimal x as x0 to speed up the sweeps
    % and obtain gradients
    x0 = b.X_start_struct;
    x0_vec_1 = gradient_optim(x0,p,b);
    x0_struct_1 = cell2struct(num2cell(x0_vec_1(1:end-1,:)),b.var_names(1:end-1)',1);

    % rerun nominal optim to check that it's the same as the first time
    [x0_vec, J0, ~, ~, lambdas, grads, hesses] = gradient_optim(x0_struct_1,p,b);
    same_as_before = ismembertol(x0_vec,x0_vec_1,1e-6);
    if ~all(same_as_before,'all')
        str = append(['First optimization of nominal parameters gave different x* than second. Using second.' newline ...
                      '#1 x*:'], newline, formattedDisplayText(x0_vec_1.'),'#2 x*:' ,newline, formattedDisplayText(x0_vec.'), 'Î” x*:', newline, formattedDisplayText(x0_vec_1.'-x0_vec.'));
        warning(str)
    end

    num_constr_nl = length(b.constraint_names);
    g_lambda_0(:,1) = combine_g_lambda(lambdas(1),x0_vec(:,1),p,b);
    g_lambda_0(:,2) = combine_g_lambda(lambdas(2),x0_vec(:,2),p,b);
    
    %% Obtain normalized post_optim sensitivity 
    disp('done single objective optimization, starting post optimality param sensitivity')
    t = tic;
    [par_x_star_par_p_post_optim, ...
     dJ_star_dp_lin_post_optim, ...
     dJ_star_dp_quad_post_optim, ...
     par_J_par_p_post_optim, ...
     delta_p_change_activity_post_optim] = local_sens_both_obj_all_param(x0_vec, J0, p, params, p_val, p_idxs, ...
                                                                    lambdas, grads, hesses, num_constr_nl);
    runtime_post_optim = toc(t);

    %% Obtain normalized re-optimization sensitivity
    disp('done post optimality param sensitivities, starting re-optimization param sensitivities')
    t = tic;
    [par_x_star_par_p_re_optim, dJstar_dp_re_optim, ...
     delta_p_change_activity_re_optim,...
     LCOE, LCOE_nom, P_var, P_var_nom, ...
     X_LCOE, X_LCOE_nom, X_Pvar, X_Pvar_nom,...
     slope_LCOE_norm, slope_Pvar_norm, ...
     slope_X_LCOE_norm, slope_X_Pvar_norm,...
     ratios,num_DVs]                      = re_optim_sens_all_param(params, p_val, ...
                                                      x0_vec, J0, g_lambda_0, ...
                                                      p, b);
    runtime_re_optim = toc(t);

end

%% Rerun optimization for re-optimization sensitivities
function [par_x_star_par_p_re_optim, ...
          dJstar_dp_re_optim, ...
          delta_p_change_activity_re_optim,...
          LCOE, LCOE_nom, P_var, Pvar_nom, ...
          X_LCOE, X_LCOE_nom, X_Pvar, X_Pvar_nom,...
          slope_LCOE_norm, slope_Pvar_norm, ...
          slope_X_LCOE_norm, slope_X_Pvar_norm,...
          ratios,num_DVs] = re_optim_sens_all_param(params, p_val, ...
                                                               x0_vec, J0, g_lambda_0, ...
                                                               p, b)
    %ratios = .8 : .1 : 1.2;
    ratios = [.9 .98 1 1.02 1.1];
    num_DVs = size(x0_vec,1)-1;
    num_constr = length(b.constraint_names) + length(b.lin_constraint_names) + 2*num_DVs;
    
    [LCOE, P_var]    = deal(zeros(length(params), length(ratios)));
    [X_LCOE, X_Pvar] = deal(zeros(length(params), length(ratios), num_DVs));
    [g_lambda_LCOE, g_lambda_Pvar] = deal(zeros(length(params), length(ratios), num_constr));
    x0 = cell2struct(num2cell(x0_vec),b.var_names',1);

    parfor i=1:length(params)
        param_name = params{i};
        [LCOE(i,:),  X_LCOE(i,:,:), ...
         g_lambda_LCOE(i,:,:),...
         P_var(i,:), X_Pvar(i,:,:),...
         g_lambda_Pvar(i,:,:)] = global_sens_reoptimize(x0, p, b, param_name, ratios, num_DVs, num_constr);
    
    end
    
    % fill in ratios == 1 (left blank since same as initial)
    X_LCOE_0_3d = permute(repmat(x0_vec(1:end-1,1).',length(params),1,sum(ratios==1)),[1 3 2]);
    X_Pvar_0_3d = permute(repmat(x0_vec(1:end-1,2).',length(params),1,sum(ratios==1)),[1 3 2]);
    g_lambda_LCOE_0_3d = permute(repmat(g_lambda_0(:,1).',length(params),1,sum(ratios==1)),[1 3 2]);
    g_lambda_Pvar_0_3d = permute(repmat(g_lambda_0(:,2).',length(params),1,sum(ratios==1)),[1 3 2]);
    LCOE(:, ratios==1) = J0(1);
    P_var(:,ratios==1) = J0(2);
    X_LCOE(:,ratios==1,:) = X_LCOE_0_3d;
    X_Pvar(:,ratios==1,:) = X_Pvar_0_3d;
    g_lambda_LCOE(:,ratios==1,:) = g_lambda_LCOE_0_3d;
    g_lambda_Pvar(:,ratios==1,:) = g_lambda_Pvar_0_3d;
    
    % check if deltas too small, indicating potential finite precision error
    delta_x_LCOE = abs(X_LCOE - X_LCOE_0_3d(:,1,:));
    delta_x_Pvar = abs(X_Pvar - X_Pvar_0_3d(:,1,:));
    delta = [delta_x_LCOE delta_x_Pvar];
    delta_too_small = (delta < 1e-6) & (delta ~= 0);
    if any(delta_too_small,'all') 
        warning(['The global sensitivity is potentially inaccurate ' ...
            'due to finite precision effects. You must either decrease ' ...
            'options.StepTolerance in gradient_optim, or increase ' ...
            'abs(ratios-1) in param_sweep.'])
    end
    
    % info for optimal design with nominal parameter values (not nominal design)
    col_nom = find(ratios==1);
    LCOE_nom = LCOE(1,col_nom);
    Pvar_nom = P_var(1,col_nom);
    X_LCOE_nom = squeeze(X_LCOE(1,col_nom,:));
    X_Pvar_nom = squeeze(X_Pvar(1,col_nom,:));
    g_lambda_LCOE_nom = squeeze(g_lambda_LCOE(1,col_nom,:)).';
    g_lambda_Pvar_nom = squeeze(g_lambda_Pvar(1,col_nom,:)).';
    
    %% Calculate objective sensitivities
    
    slope_LCOE = get_slope(LCOE, ratios);
    slope_Pvar = get_slope(P_var, ratios);
    
    slope_LCOE_norm = slope_LCOE.' / LCOE_nom; % normalize
    slope_Pvar_norm = slope_Pvar.' / Pvar_nom;

    if all(~isfinite(slope_LCOE),'all') || all(~isfinite(slope_Pvar),'all')
        msg = ['All slopes are NaN, meaning all optimizations failed. ' ...
            'This might be because no feasible solution can be found. ' ...
            'slope_LCOE = ', num2str(slope_LCOE(:).'), ' and slope_Pvar = ', num2str(slope_Pvar(:).')];
        error(msg)
    end
    
    %% Calculate design variable sensitivities
    slope_X_LCOE = get_slope(X_LCOE, ratios);
    slope_X_Pvar = get_slope(X_Pvar, ratios);
    
    slope_X_LCOE_norm  = slope_X_LCOE ./ X_LCOE_nom.'; % normalize
    slope_X_Pvar_norm  = slope_X_Pvar ./ X_Pvar_nom.';
    
    %% calculate lagrange multiplier and constraint sensitivities
    dlambda_g_dp_LCOE = get_slope(g_lambda_LCOE, ratios);
    dlambda_g_dp_Pvar = get_slope(g_lambda_Pvar, ratios);
    delta_p_LCOE = -g_lambda_LCOE_nom ./ dlambda_g_dp_LCOE;
    delta_p_Pvar = -g_lambda_Pvar_nom ./ dlambda_g_dp_Pvar;
    delta_p_LCOE_norm = delta_p_LCOE ./ p_val.';
    delta_p_Pvar_norm = delta_p_Pvar ./ p_val.';

    %% assign normalized outputs - fixme ignoring slope_Pvar for now
    dJstar_dp_re_optim = slope_LCOE_norm;
    par_x_star_par_p_re_optim = slope_X_LCOE_norm.';
    delta_p_change_activity_re_optim = delta_p_LCOE_norm;
    
end

function slope = get_slope(y, x)
    % y is a 2D (ie J*) or 3D (ie X*) array, and x is a 1D vector (ie ratios), 
    % then slope is similar to
    % (y(:,end,:) - y(:,1,:) ./ (x(end) - x(1))
    % but if y contains NaNs at those indices, then more inner indices are used.

    assert(size(x,2) == size(y,2))
    assert(ndims(y) <= 3)
    assert(size(x,1) == 1)
    x = x.'; % make row vector into col vector so indexing below works

    y_for_nans = y(:,:,1); % deal with case where ndims(y) > 2 - this works
    % because the presence of a NaN for 3D input (X*) is determined by the first two indices only

    % if there are no NaNs, idx_first will be all ones and idx_last will be
    % all size(result,2). Below calculates correct indices when there are NaNs.
    [~,sub_dim2_first] = max( ~isnan(y_for_nans), [], 2);
    flipped = flip(y_for_nans,2);
    [~,sub_dim2_last_flipped] = max( ~isnan(flipped), [], 2);
    sub_dim2_last = size(y,2) + 1 - sub_dim2_last_flipped;
    [sub_dim1, sub_dim3] = meshgrid(1:size(y,1), 1:size(y,3));
    sub_dim2_first = repmat(sub_dim2_first,[1 size(y,3)]);
    sub_dim2_last  = repmat(sub_dim2_last, [1 size(y,3)]);
    idx_first = sub2ind(size(y), sub_dim1.', sub_dim2_first, sub_dim3.');
    idx_last  = sub2ind(size(y), sub_dim1.', sub_dim2_last,  sub_dim3.');

    % using idx_first and idx_last, calculate slope
    y_first = y(idx_first);
    y_last = y(idx_last);
    x_first = x(sub_dim2_first);
    x_last = x(sub_dim2_last);
    slope = (y_last - y_first) ./ (x_last - x_first);
    
end

function [LCOE, X_LCOE, g_lambda_LCOE, ...
         P_var, X_Pvar, g_lambda_Pvar] = global_sens_reoptimize(x0, p, b, ...
                                                                    param_name, ratios, num_DVs, num_constr)
    % Brute force parameter sensitivity sweep (reoptimize for each param value)

    [LCOE,P_var] = deal(zeros(1,length(ratios)));
    [X_LCOE,X_Pvar] = deal(zeros(length(ratios),num_DVs));
    [g_lambda_LCOE,g_lambda_Pvar] = deal(zeros(length(ratios),num_constr));

    var_nom = p.(param_name);

    dry_run = false; % true means use random numbers, false means actual optimization

    parfor j=1:length(ratios)
        if ratios(j) ~=1   
            new_p = p;
            new_p.(param_name) = ratios(j) * var_nom;
            if dry_run
                [Xs_opt, obj_opt, flag] = deal(rand(num_DVs+1,2),rand(2,1),[1 1]);
                g_lambda_LCOE_tmp = rand(num_constr,1);
                g_lambda_Pvar_tmp = rand(num_constr,1);
            else
                [Xs_opt, obj_opt, flag, ~, lambdas] = gradient_optim(x0,new_p,b);
                g_lambda_LCOE_tmp = combine_g_lambda(lambdas(1),Xs_opt(:,1),new_p,b);
                g_lambda_Pvar_tmp = combine_g_lambda(lambdas(2),Xs_opt(:,2),new_p,b);
            end
            
            if flag(1) >= 1
                LCOE(j) = obj_opt(1);
                X_LCOE(j,:) = Xs_opt(1:end-1,1);
                g_lambda_LCOE(j,:) = g_lambda_LCOE_tmp;
            else
                [X_LCOE(j,:),LCOE(j),g_lambda_LCOE(j,:)] = deal(NaN);
            end
            if flag(2) >= 1
                P_var(j) = obj_opt(2);
                X_Pvar(j,:)= Xs_opt(1:end-1,2); 
                g_lambda_Pvar(j,:) = g_lambda_Pvar_tmp;
            else
                [X_Pvar(j,:), P_var(j),g_lambda_Pvar(j,:)] = deal(NaN);
            end
        end
    end   

end

function g_lambda = combine_g_lambda(lambda,X,p,b)
% returns a vector containing lambda where constraints are active,
% and g where constraints are inactive.

    all_lambda = [lambda.ineqnonlin; lambda.ineqlin; lambda.lower; lambda.upper];
    idx_g = all_lambda == 0;

    % sensitivities use g<=0 convention
    [~,~,g_nl] = simulation(X,p);
    [A_lin, b_lin] = lin_ineq_constraints(p);
    g_lin = A_lin*X(1:size(A_lin,2)) - b_lin;
    g_lb = b.X_mins - X(1:end-1);
    g_ub = X(1:end-1) - b.X_maxs;
    all_g = [-g_nl.'; g_lin; g_lb; g_ub];

    g_lambda = all_lambda;
    g_lambda(idx_g) = all_g(idx_g);

end

